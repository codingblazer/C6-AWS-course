Amazon Cloudwatch
------------------
It's a performance monitoring tool that collects metrics for things like EC2, can be used to setup alarms and also used to collect the logs from these resources. 

Metrics: These are time audit data that's sent from service like EC2 to CloudWatch and it then shows them to us in graphical manner. we can not just collect them from AWS services but also from on-premises resources and then use those metrics to do autoscaling, understand the performance and make optimisations accordingly. In case of EC2 they are sent every 5 mins and can be made to be sent every 1 min which is detailed monitoring and we have to pay for it.
Now on our service like EC2, they send default metrics but we can install a Unified CloudWatch Agent which also sends VIMP metrics which are disk utilization and memory usage and much more which are not sent in default case and this also works with both AWS and on-premises resources. These are internal system-level metrics that can be captured for diff OS versions, AWD service and on-premises services + with help of StatsD and collectD protocols. Also its IMP for exam to know that agent based logs are sent to cloudwatch as soon as they are generated and thus even if node terminates, logs will be present in cloudwatch. It is also imp for exam to know what all diff things as compared to default does this agent captures which is present here: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html
We can also send custom metrics from services like Ec2 to cloudwatch by using the API of cloudwatch directly in additon to above => these custom metrics can be high resolution (1 sec granulity) or standard (one min granulity and for custom metrics this is the default). 

Alarms: These are the actions you can take based on the metrics like we saw in ASG for autoscaling. They can be single metric alarm which perform one or more action based on alarm or composite alarm which perform one or more action for set of alarms (if all or one triggers, then do those actions). Diff alarms states are OK (below threshold), IN ALARM (above threshold) and INSUFFICIENT DATA (not have enough info as of now) 

Logs: They are centralized collection system for 1) system logs 2) application logs. Note that if the Unified Cloudwatch agent is installed on your service, then it will not just send metrics we told above but also the system level logs to the cloudwatch and this is the reason this agent is called unified because it sends both metrics and logs to cloudwatch.
The logs collected by cloudwatch can then be passed to s3 or Kinesis Data Streams and Kinesis Data Firehose. We can also define expiration policies for the logs, 

Cloudwatch Events/Eventbus: These are the events that are sent when things like state change in resources happen and we studied event bridge which does same thing as this.

Lab: Send custom metric from EC2 => See file in folder ec2-custom-metrics => Launch a t2 micro instance => Now copy the instance id and paste in file for the commands => these commands are sending dummy metrics like latency to cloudwatch for specific instance we created and in real life we can run some script on ec2 which will collect metrics we want and send them to cloudewatch through AWS API like this only. Next create IAM role to allow putting metrics intoo cloudwatch by ec2 =>  create role, ec2, Cloudwatchagentserver policy, create => select instance, actions, security, modify IAM role, select role we create, done => Ssh into your instance and run first 2 commands from the file which will send dummy data => Now open cloudwatch => all metrics => my custom namespace whcih we created => click and it will show 2 metrics latency and bytes we sent.

LAB: Create cloudwatch alarm => Cloudwatch => all alarms, select metric, my custom metric, select latency metric, statistics max, period 1 min, greater than 30, next, add ec2 action when state is IN ALARM, terminate the instance, next, name, create => from the file in folder copy 3rd command and replace the instance id and run it from the instance and if you see this command is sending dummy latency of 35 and thus alarm should trigger and you can see the ec2 being terminated.

Lab: Go to cloudwatch and see logs on left => Top level is log group and it log group name tells which service and what name/object of that service logs are for. Inside log group are the log streams and inside log streams we have log events or actual logs. These events will have start and end event and other info events in between each having things like function ran for what time, json code that went to sqs, etc.Inside log group, go to metrics filter tab => this allow to filter the events and count things like values etc, in subscription filter tab where we can choose services like lambda kenises for analytics where cloudwatch logs from this log group will go for futher analysis, Choose log insights from left => select logs groups and then you can run sql query on top of them like most 20 recent logs 

AWS Cloudtrail
--------------
CloudTrail is a service that you can use for capturing information about the API actions that are happening in your AWS account like launch an EC2, create Lambda function or modify every thing is API action whether on management console, the CLI, the API, or the SDK and these are logged by CloudTrail so you can monitor it for auditing purposes i.e. who did what on which resource at what time. 

There are 3 types of events in cloudtrail - Management events which are events like creation, deletion, modification of resources like ec2 and then we have Data events which tell detailed info like what was done inside the resource itself like file upload etc and finally we have insight events which are generally used to know of any suspicious write API calls.

Management events (API actions) are logged and retained for 90 days which can be extended by creating a trail in cloudtrail that will forward these events to s3 for permanent retention. This trail can also send these events to not just s3 but also to cloudwatch logs which then can be used to set alarms on top of cloudwatch logs. We can also make a setup such that eventbus/cloudwatch events has a rule to pick specifc events from cloudtrail and trigger actions like lambda function for some specific events. Also we can integrate a trail with SNS to trigger notifications directly when log is created. While creating trail, we can also enable File integrity validation which ensures that the logs written by trail to s3 or anywhere else can't be tampered i.e. some employee editing the log to change his name to someone else name for a action. 
Each trail can be within a region or it can be applied to all regions.

Lab: Go to AWS cloudtrail => dashboard on left and it will show events but choose event history on left which show same in detail => in this you might see some events (API actions) like instance termination which we did earlier and if you click that event or API action you will see details like who did it, his account etc => Now all this event history as told will retain in this cloudtrail for 90 days because we havent created any trail yet => Go to trails on the left, create, create new s3, new encryption key create and thus give any name, log file validation enabled so as to know log file is not tampered. Now optionally we can create cloudwatch logs as output (like we have done into s3), new role for it give any name => Event types we can have management events and lets choose data events as well and for that below we have to given destination like lambda, etc => lets skip data events for now and create this trail which will ensiure all API actions go to both s3 and cloudwatch logs. 

Amazon EventBridge/Cloudwatch events Recap: So there are sources like AWS services, custom apps etc generating events and these events are picked by eventbus and inside eventbus, we based on rules specified, perform actions on these events like triggering lambda, etc which are called targets.

Lab: In this section, we will use the cloudtrail and eventbus together i.e. when ec2 instance terminate API action is done, it will send API event to cloudtrail and this event will go to s3 and thus on going to s3, we will trigger a lanbda function for this event which will then write something to cloudwatch logs (although trail is writing already to cloudwatch logs directly as well) => Lambda, create, choose blueprintm, hello world, paste code from folder cloudtrail logEc2stopinstance => paste it and deploy
Go to eventbridge, rules, create rule, name, event pattern, predefined pattern by service, AWS + EC2 + AWS API call via cloudtrail, specific operaton, StopInstance => Now this rule is watching for event of ec2 termination type coming from cloudtrail => target, lambda function,  select our lambda function and create.
Now create ec2 instance and stop it => in cloudtrail you should see the event for it => eventbus would have picked it as we specified rule to watch it from cloudtrail, and thus lambda will be trigger and it would have added log in cloudwatch logs. 